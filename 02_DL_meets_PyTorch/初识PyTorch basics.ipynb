{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一课 当深度学习遇上PyTorch\n",
    "\n",
    "在这节课中，我们主要展示了PyTorch的使用方法，以及如何用PyTorch实现一个线性回归算法\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、有关Tensor和Autograd变量的练习\n",
    "### 1. Tensor\n",
    "#### a. 产生Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.1'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch  #导入torch包\n",
    "torch.__version__ #显示当前PyTorch版本号，笔者用的是0.1.12_2，有些命令可能在新的版本下无法执行，请参考PyTorch文件找到最新的相应命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3053, 0.1961, 0.1889],\n",
       "        [0.4665, 0.7936, 0.7861],\n",
       "        [0.6334, 0.5552, 0.8624],\n",
       "        [0.0520, 0.8022, 0.7135],\n",
       "        [0.1884, 0.9157, 0.0608]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)  #产生一个5*3的tensor，随机取值\n",
    "x  #显示x的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(5, 3) #产生一个5*3的Tensor，元素都是1\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.zeros(2, 5, 3) #产生一个5*3的Tensor，元素都是1\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7861)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1889, 0.7861, 0.8624, 0.7135, 0.0608])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Tensor的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3053, 1.1961, 1.1889],\n",
       "        [1.4665, 1.7936, 1.7861],\n",
       "        [1.6334, 1.5552, 1.8624],\n",
       "        [1.0520, 1.8022, 1.7135],\n",
       "        [1.1884, 1.9157, 1.0608]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = torch.FloatTensor([[0.3297,0.7021,0.1119],[0.6668,0.6904,0.1953],[0.6683,0.4260,0.2950],[0.0899,0.4099,0.0882],[0.4675,0.8369,0.1926]])\n",
    "z = x + y #两个tensor可以直接相加\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的语句展示了两个tensor按照矩阵的方式相乘，注意x的尺寸是5*3，y的尺寸也是5*3无法进行矩阵乘法，所以先将y进行转置。\n",
    "转置操作可以用.t来完成，也可以用<!-- lang:python-->.transpose(0, 1)来完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6903, 0.6903, 0.6903, 0.6903, 0.6903],\n",
       "        [2.0462, 2.0462, 2.0462, 2.0462, 2.0462],\n",
       "        [2.0510, 2.0510, 2.0510, 2.0510, 2.0510],\n",
       "        [1.5677, 1.5677, 1.5677, 1.5677, 1.5677],\n",
       "        [1.1649, 1.1649, 1.1649, 1.1649, 1.1649]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = x.mm(y.t()) #x乘以y的转置\n",
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Tensor与numpy.ndarray之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np #导入numpy包\n",
    "a = np.ones([5, 3]) #建立一个5*3全是1的二维数组（矩阵）\n",
    "print(a)\n",
    "b = torch.from_numpy(a) #利用from_numpy将其转换为tensor\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.FloatTensor(a) #另外一种转换为tensor的方法，类型为FloatTensor，还可以使LongTensor，整型数据类型\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()  #从一个tensor转化为numpy的多维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor和numpy的最大区别在于tensor可以在GPU上运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[1.3053, 1.1961, 1.1889],\n",
      "        [1.4665, 1.7936, 1.7861],\n",
      "        [1.6334, 1.5552, 1.8624],\n",
      "        [1.0520, 1.8022, 1.7135],\n",
      "        [1.1884, 1.9157, 1.0608]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():  #检测本机器上有无GPU可用\n",
    "    x = x.cuda() #返回x的GPU上运算的版本\n",
    "    y = y.cuda()\n",
    "    print(x + y) #tensor可以在GPU上正常运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3053, 1.1961, 1.1889],\n",
      "        [1.4665, 1.7936, 1.7861],\n",
      "        [1.6334, 1.5552, 1.8624],\n",
      "        [1.0520, 1.8022, 1.7135],\n",
      "        [1.1884, 1.9157, 1.0608]], device='cuda:0')\n",
      "tensor([[1.3053, 1.1961, 1.1889],\n",
      "        [1.4665, 1.7936, 1.7861],\n",
      "        [1.6334, 1.5552, 1.8624],\n",
      "        [1.0520, 1.8022, 1.7135],\n",
      "        [1.1884, 1.9157, 1.0608]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  #检测本机器上有无GPU可用\n",
    "    device = torch.device(\"cuda\")          # 选择一个CUDA设备\n",
    "    y = torch.ones_like(x, device=device)  # 在GPU上直接创建张量\n",
    "    x = x.to(device)                       # 也可以直接加载``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # 转回到CPU上``.to``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 有关自动微分变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2, 2), requires_grad=True)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x2bf99d30790>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2  #可以按照Tensor的方式进行计算\n",
    "y.grad_fn  \n",
    "#注：在新版本PyTorch中，可以用.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MulBackward0 at 0x2bf981d1480>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y  #可以进行各种符合运算\n",
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.mean(y * y)  #也可以进行复合运算\n",
    "z.data #.data属性可以返回z所包裹的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** backward可以实施反向传播算法，并计算所有计算图上叶子节点的导数（梯度）信息。注意，由于z和y都不是叶子节点，所以都没有梯度信息）**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "tensor([[1.5000, 1.5000],\n",
      "        [1.5000, 1.5000]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29976\\2704189224.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(z.grad)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29976\\2704189224.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(y.grad)\n"
     ]
    }
   ],
   "source": [
    "z.backward() #梯度反向传播\n",
    "print(z.grad)\n",
    "print(y.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的例子中，我们让矩阵x反复作用在向量x上，系统会自动记录中间的依赖关系和长路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([[0.01, 0.02]], requires_grad = True) #创建一个1*2的tensor（1维向量）\n",
    "x = torch.ones(2, 2, requires_grad = True) #创建一个2*2的矩阵型tensor\n",
    "for i in range(10):\n",
    "    s = s.mm(x)  #反复用s乘以x（矩阵乘法），注意s始终是1*2的tensor\n",
    "z = torch.mean(s) #对s中的各个元素求均值，得到一个1*1的scalar（标量，即1*1张量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37.1200, 37.1200],\n",
      "        [39.6800, 39.6800]])\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_29976\\3972389255.py:3: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(s.grad)  #s不是叶节点，没有梯度信息\n"
     ]
    }
   ],
   "source": [
    "z.backward() #在具有很长的依赖路径的计算图上用反向传播算法计算叶节点的梯度\n",
    "print(x.grad)  #x作为叶节点可以获得这部分梯度信息\n",
    "print(s.grad)  #s不是叶节点，没有梯度信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、利用PyTorch实现简单的线性回归算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 准备数据\n",
    "\n",
    "在这里，我们人为生成一些样本点作为我们的原始数据\n",
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0.0000,   1.0101,   2.0202,   3.0303,   4.0404,   5.0505,   6.0606,\n",
      "          7.0707,   8.0808,   9.0909,  10.1010,  11.1111,  12.1212,  13.1313,\n",
      "         14.1414,  15.1515,  16.1616,  17.1717,  18.1818,  19.1919,  20.2020,\n",
      "         21.2121,  22.2222,  23.2323,  24.2424,  25.2525,  26.2626,  27.2727,\n",
      "         28.2828,  29.2929,  30.3030,  31.3131,  32.3232,  33.3333,  34.3434,\n",
      "         35.3535,  36.3636,  37.3737,  38.3838,  39.3939,  40.4040,  41.4141,\n",
      "         42.4242,  43.4343,  44.4444,  45.4545,  46.4646,  47.4747,  48.4848,\n",
      "         49.4949,  50.5051,  51.5152,  52.5253,  53.5354,  54.5455,  55.5556,\n",
      "         56.5657,  57.5758,  58.5859,  59.5960,  60.6061,  61.6162,  62.6263,\n",
      "         63.6364,  64.6465,  65.6566,  66.6667,  67.6768,  68.6869,  69.6970,\n",
      "         70.7071,  71.7172,  72.7273,  73.7374,  74.7475,  75.7576,  76.7677,\n",
      "         77.7778,  78.7879,  79.7980,  80.8081,  81.8182,  82.8283,  83.8384,\n",
      "         84.8485,  85.8586,  86.8687,  87.8788,  88.8889,  89.8990,  90.9091,\n",
      "         91.9192,  92.9293,  93.9394,  94.9495,  95.9596,  96.9697,  97.9798,\n",
      "         98.9899, 100.0000])\n",
      "tensor([  9.3250,  -5.0602,  15.2472,  18.1254,  10.3284,   2.7803,  -3.8427,\n",
      "          6.1086,   4.6494,  18.1115, -14.0075,   7.9564,  20.5666,  13.9144,\n",
      "         19.1142,   4.3070,  13.2468,  36.0651,  13.5525,  25.4994,   7.6976,\n",
      "         28.1358,  14.2516,  22.6823,  29.2668,  17.1037,  17.1080,  42.7659,\n",
      "         22.5494,  39.3285,  32.4820,  16.8064,  54.3042,  30.8432,  24.8344,\n",
      "         29.5254,  54.6358,  43.9267,  43.1825,  46.9956,  59.0331,  64.3508,\n",
      "         50.1565,  46.6327,  49.9662,  43.3073,  59.6189,  61.9007,  41.7546,\n",
      "         72.7414,  49.8448,  48.2465,  54.8195,  40.6030,  45.7778,  54.8179,\n",
      "         45.4478,  61.7060,  62.1591,  66.5362,  52.4990,  70.8191,  80.6766,\n",
      "         63.6302,  65.9790,  85.5169,  66.1976,  49.0457,  69.2792,  72.1164,\n",
      "         81.7630,  52.9511,  58.4762,  72.5316,  74.4440,  62.4069,  80.3465,\n",
      "         72.6654,  82.3563,  74.0739,  69.5347,  76.2213,  87.5724,  83.5142,\n",
      "         89.2174,  58.4234,  84.8110,  90.5466,  75.3729,  83.4560,  84.7907,\n",
      "         98.0242, 104.6398,  94.3260,  90.0946,  86.0964, 100.5033, 124.9968,\n",
      "        104.7137, 118.1804])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 100,100).type(torch.FloatTensor) #linspace可以生成0-100之间的均匀的100个数字\n",
    "rand = torch.randn(100) * 10 #随机生成100个满足标准正态分布的随机数，均值为0，方差为1.将这个数字乘以10，标准方差变为10\n",
    "y = x + rand #将x和rand相加，得到伪造的标签数据y。所以(x,y)应能近似地落在y=x这条直线上\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  1.0101,  2.0202,  3.0303,  4.0404,  5.0505,  6.0606,  7.0707,\n",
      "         8.0808,  9.0909, 10.1010, 11.1111, 12.1212, 13.1313, 14.1414, 15.1515,\n",
      "        16.1616, 17.1717, 18.1818, 19.1919, 20.2020, 21.2121, 22.2222, 23.2323,\n",
      "        24.2424, 25.2525, 26.2626, 27.2727, 28.2828, 29.2929, 30.3030, 31.3131,\n",
      "        32.3232, 33.3333, 34.3434, 35.3535, 36.3636, 37.3737, 38.3838, 39.3939,\n",
      "        40.4040, 41.4141, 42.4242, 43.4343, 44.4444, 45.4545, 46.4646, 47.4747,\n",
      "        48.4848, 49.4949, 50.5051, 51.5152, 52.5253, 53.5354, 54.5455, 55.5556,\n",
      "        56.5657, 57.5758, 58.5859, 59.5960, 60.6061, 61.6162, 62.6263, 63.6364,\n",
      "        64.6465, 65.6566, 66.6667, 67.6768, 68.6869, 69.6970, 70.7071, 71.7172,\n",
      "        72.7273, 73.7374, 74.7475, 75.7576, 76.7677, 77.7778, 78.7879, 79.7980,\n",
      "        80.8081, 81.8182, 82.8283, 83.8384, 84.8485, 85.8586, 86.8687, 87.8788,\n",
      "        88.8889, 89.8990])\n",
      "tensor([ 90.9091,  91.9192,  92.9293,  93.9394,  94.9495,  95.9596,  96.9697,\n",
      "         97.9798,  98.9899, 100.0000])\n",
      "tensor([  9.3250,  -5.0602,  15.2472,  18.1254,  10.3284,   2.7803,  -3.8427,\n",
      "          6.1086,   4.6494,  18.1115, -14.0075,   7.9564,  20.5666,  13.9144,\n",
      "         19.1142,   4.3070,  13.2468,  36.0651,  13.5525,  25.4994,   7.6976,\n",
      "         28.1358,  14.2516,  22.6823,  29.2668,  17.1037,  17.1080,  42.7659,\n",
      "         22.5494,  39.3285,  32.4820,  16.8064,  54.3042,  30.8432,  24.8344,\n",
      "         29.5254,  54.6358,  43.9267,  43.1825,  46.9956,  59.0331,  64.3508,\n",
      "         50.1565,  46.6327,  49.9662,  43.3073,  59.6189,  61.9007,  41.7546,\n",
      "         72.7414,  49.8448,  48.2465,  54.8195,  40.6030,  45.7778,  54.8179,\n",
      "         45.4478,  61.7060,  62.1591,  66.5362,  52.4990,  70.8191,  80.6766,\n",
      "         63.6302,  65.9790,  85.5169,  66.1976,  49.0457,  69.2792,  72.1164,\n",
      "         81.7630,  52.9511,  58.4762,  72.5316,  74.4440,  62.4069,  80.3465,\n",
      "         72.6654,  82.3563,  74.0739,  69.5347,  76.2213,  87.5724,  83.5142,\n",
      "         89.2174,  58.4234,  84.8110,  90.5466,  75.3729,  83.4560])\n",
      "tensor([ 84.7907,  98.0242, 104.6398,  94.3260,  90.0946,  86.0964, 100.5033,\n",
      "        124.9968, 104.7137, 118.1804])\n"
     ]
    }
   ],
   "source": [
    "x_train = x[: -10]\n",
    "print(x_train)\n",
    "x_test = x[-10 :]\n",
    "print(x_test)\n",
    "\n",
    "y_train = y[: -10]\n",
    "print(y_train)\n",
    "\n",
    "y_test = y[-10 :]\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将生成的训练数据点画在图上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #导入画图的程序包\n",
    "plt.figure(figsize=(10,8)) #设定绘制窗口大小为10*8 inch\n",
    "plt.plot(x_train, y_train, color='green', marker='o', linestyle='dashed',\n",
    "     linewidth=2, markersize=1) \n",
    "plt.xlabel('X') #添加X轴的标注\n",
    "plt.ylabel('Y') #添加Y周的标注\n",
    "plt.show() #将图形画在下面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 构造模型，计算损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的代码中，需要注意expand_as和mul的使用。首先，a的维度为1，x的维度为100*1的Tensor，这两者不能直接相乘，因为维度不同。\n",
    "\n",
    "所以，先要将a升维成1*1的Tensor。这就好比将原本在直线上的点被升维到了二维平面上，同时直线仍然在二维平面中。\n",
    "\n",
    "```expand_as(x)```可以将张量升维成与x同维度的张量。所以如果a = 1, x为尺寸为100，那么，\n",
    "\n",
    "a.expand_as(x)$ = (1, 1, \\cdot\\cdot\\cdot, 1)^T$\n",
    "\n",
    "```x * y```为两个1维张量的乘积，计算结果：\n",
    "\n",
    "$(x * y)_i = x_i \\cdot y_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661,\n",
      "        0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661, 0.9661],\n",
      "       grad_fn=<ExpandBackward0>)\n",
      "tensor([0.2171], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2171,  1.1930,  2.1689,  3.1448,  4.1207,  5.0966,  6.0725,  7.0484,\n",
       "         8.0242,  9.0001,  9.9760, 10.9519, 11.9278, 12.9037, 13.8796, 14.8555,\n",
       "        15.8314, 16.8073, 17.7831, 18.7590, 19.7349, 20.7108, 21.6867, 22.6626,\n",
       "        23.6385, 24.6144, 25.5903, 26.5661, 27.5420, 28.5179, 29.4938, 30.4697,\n",
       "        31.4456, 32.4215, 33.3974, 34.3733, 35.3492, 36.3250, 37.3009, 38.2768,\n",
       "        39.2527, 40.2286, 41.2045, 42.1804, 43.1563, 44.1322, 45.1080, 46.0839,\n",
       "        47.0598, 48.0357, 49.0116, 49.9875, 50.9634, 51.9393, 52.9152, 53.8911,\n",
       "        54.8669, 55.8428, 56.8187, 57.7946, 58.7705, 59.7464, 60.7223, 61.6982,\n",
       "        62.6741, 63.6499, 64.6258, 65.6017, 66.5776, 67.5535, 68.5294, 69.5053,\n",
       "        70.4812, 71.4571, 72.4329, 73.4088, 74.3847, 75.3606, 76.3365, 77.3124,\n",
       "        78.2883, 79.2642, 80.2401, 81.2160, 82.1918, 83.1677, 84.1436, 85.1195,\n",
       "        86.0954, 87.0713], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad = True)\n",
    "print(a.expand_as(x_train))\n",
    "b = torch.rand(1, requires_grad = True)\n",
    "print(b)\n",
    "\n",
    "predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean((predictions - y_train) ** 2)  #计算损失函数\n",
    "loss.backward() #开始反向传播梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2210])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#开始梯度下降，其中0.001为学习率\n",
    "a.data.add_(- 0.001 * a.grad.data) \n",
    "b.data.add_(- 0.001 * b.grad.data)\n",
    "\n",
    "#注意我们无法改变一个tensor，而只能对tensor的data属性做更改\n",
    "#所有函数加“_”都意味着需要更新调用者的数值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 训练模型的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. 错误版本\n",
    "\n",
    "错误在于，每一步迭代周期没有将a和b的梯度（grad）数值设置为0，导致每一步backward候梯度就会不断累加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: tensor([0.4045], requires_grad=True) tensor([0.8883], requires_grad=True)\n",
      "loss: tensor(1000.1840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(295.1864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(206.4501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(900.2784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1076.3436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(404.6748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(144.0668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(782.9317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1123.9491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(528.0045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(111.9738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(655.5501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1139.9951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(657.3906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.1965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(526.1745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1123.4695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(784.6655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(144.7202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(402.9698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1075.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(901.7950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(207.4914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(293.7117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(998.8596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1001.3857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(296.5468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(205.2959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(898.6394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1077.1501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(406.2647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(143.3015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(781.0775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1124.3046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(529.7181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(111.6404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(653.5927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1139.8722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(659.1140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.3097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(524.2302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1122.8680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(786.2822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(145.2653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(401.1534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1074.3636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(903.1955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(208.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(292.1295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(997.4191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1002.4714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(297.8013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(204.0375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(896.8884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1077.8425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(407.7497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(142.4356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(779.1161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1124.5491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(531.3287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(111.2100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(651.5321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1139.6405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(660.7354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.3292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(522.1877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1122.1615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(787.7997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(145.7201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(399.2446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1073.2136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(904.4984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(209.2724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(290.4599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(995.8832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1003.4634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(298.9720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(202.6976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(895.0490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1078.4446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(409.1545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(141.4938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(777.0717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1124.7076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(532.8622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(110.7090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(649.3954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1139.3280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(662.2841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.2835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(520.0762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1121.3800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(789.2474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(146.1147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(397.2737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1071.9944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(905.7358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(210.0640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(288.7354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(994.2847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1004.3939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(300.0922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(201.3096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(893.1528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1078.9908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(410.5132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(140.5109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(774.9789, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1124.8147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(534.3544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(110.1738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(647.2186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.9703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(663.7954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.2099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(517.9331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1120.5608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(790.6634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(146.4875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(395.2794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1070.7451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(906.9473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(210.8398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(286.9958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(992.6644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1005.3039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(301.2019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(199.9143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(891.2430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1079.5217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(411.8666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(139.5280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(772.8804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1124.9136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(535.8466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.6457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(645.0439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.6105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(665.3126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.1502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(515.8001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1119.7456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(792.0898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(146.8805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(393.3033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1069.5071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(908.1736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(211.6417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(285.2824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(991.0617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1006.2338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(302.3430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(198.5531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(889.3593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1080.0782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(413.2570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(138.5869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(770.8162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1125.0435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(537.3799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(642.9125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.2887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(666.8748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.1451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(513.7183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1118.9750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(793.5662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(147.3338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(391.3862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1068.3202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(909.4550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(212.5087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(283.6354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(989.5182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1007.2236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(303.5541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(197.2649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(887.5411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1080.6993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(414.7210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(137.7247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(768.8248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1125.2428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(538.9913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(640.8598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.0406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(668.5192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.2296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(511.7220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1118.2837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(795.1273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(147.8809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(389.5607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1067.2175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(910.8232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(213.4732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(282.0855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(988.0638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1008.3034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(304.8655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(196.0792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(885.8181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1081.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(416.2878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(136.9696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(766.9330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1125.5382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(540.7070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(638.9118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1137.8917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(670.2687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(509.8348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1117.6940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(796.7950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(148.5440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(387.8488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1066.2201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(912.2995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(214.5550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(280.6531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(986.7181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1009.4918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(306.2948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(195.0140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(884.2064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1082.2363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(417.9727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(136.3371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(765.1558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1125.9434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(542.5403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(637.0814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1137.8538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(672.1354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(112.7508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(508.0676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1117.2167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(798.5790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(149.3316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(386.2583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1065.3354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(913.8910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(215.7609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(279.3433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(985.4860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1010.7938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(307.8468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(194.0717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(882.7091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1083.1722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(419.7782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(135.8276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(763.4938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1126.4595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(544.4916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(635.3661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1137.9252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(674.1171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(113.1945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(506.4156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1116.8468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(800.4741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(150.2376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(384.7827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1064.5569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(915.5894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(217.0816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(278.1471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(984.3579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1012.1985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(309.5096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(193.2416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(881.3146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1084.2065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(421.6900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(135.4277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(761.9327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1127.0708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(546.5444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(633.7502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.0875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(676.1943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(113.7404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(504.8601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1116.5643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(802.4592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(151.2411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(383.4008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1063.8622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(917.3723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(218.4948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(277.0415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(983.3108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1013.6827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(311.2593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(192.4982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(879.9971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1085.3146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(423.6822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(135.1103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(760.4448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1127.7494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(548.6703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(632.2033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.3114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(678.3376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(114.3583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(503.3702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1116.3381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(804.5033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(152.3105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(382.0806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1063.2186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(919.2062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(219.9667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(275.9928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(982.3091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1015.2101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(313.0602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(191.8066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(878.7198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1086.4583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(425.7177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(134.8389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(758.9930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1128.4572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(550.8317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(630.6876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.5583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(680.5084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(115.0096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(501.9063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1116.1278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(806.5660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(153.4060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(380.7812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1062.5848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(921.0504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(221.4574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(274.9597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(981.3115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1016.7400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(314.8717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(191.1252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(877.4422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1087.5972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(427.7559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(134.5720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(757.5347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1129.1523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(552.9874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(629.1613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.7860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(682.6653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(115.6522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(500.4274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1115.8931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(808.6069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(154.4858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(379.4613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1061.9208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(922.8657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(222.9249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(273.9014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(980.2791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1018.2328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(316.6526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(190.4130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(876.1236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1088.6912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(429.7552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(134.2685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(756.0312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1129.7961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(555.0966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(627.5847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.9557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(684.7673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(116.2462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(498.8932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1115.5939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(810.5853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(155.5105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(378.0822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1061.1873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(924.6111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(224.3307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(272.7793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(979.1722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1019.6493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(318.3651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(189.6326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(874.7272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1089.7035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(431.6799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(133.8924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(754.4463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1130.3527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(557.1243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(625.9232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1139.0331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(686.7820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(116.7583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(497.2711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1115.1981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(812.4705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(156.4485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(376.6122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1060.3534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(926.2574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(225.6451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(271.5636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(977.9618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1020.9616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(319.9812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(188.7563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(873.2249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1090.6061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(433.5031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(133.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(752.7535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1130.7958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(559.0459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(624.1527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.9940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(688.6859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.1665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(495.5395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1114.6840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(814.2406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(157.2799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(375.0325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1059.4001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(927.7852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(226.8498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(270.2377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(976.6316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1022.1526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(321.4848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(187.7693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(871.6027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1091.3860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(435.2112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(132.8321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(750.9416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.1144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(560.8499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(622.2643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.8303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(690.4704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.4626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(493.6917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1114.0457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(815.8900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(157.9987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(373.3379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1058.3232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(929.1912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(227.9414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(268.7986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(975.1793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1023.2206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(322.8749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(186.6711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(869.8605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1092.0427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(436.8053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(132.1372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(749.0131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.3116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(562.5403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(620.2625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.5468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(692.1412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.6535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(491.7337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1113.2893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(817.4260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(158.6140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(371.5378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1057.1321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(930.4848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(228.9316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(267.2583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(973.6174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1024.1794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(324.1656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(185.4756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(868.0137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1092.5933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(438.3026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(131.3494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(746.9846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(564.1356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(618.1665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1138.1639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(693.7200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.7599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(489.6879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1112.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(818.8730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(159.1490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(369.6552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1055.8524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(931.6935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(229.8454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(265.6420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(971.9720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1025.0558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(325.3838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(184.2106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(866.0898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1093.0653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(439.7307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(130.4980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(744.8859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.4255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(565.6657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(616.0075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1137.7126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(695.2369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.8142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(487.5861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1111.5262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(820.2628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(159.6373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(367.7247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1054.5164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(932.8482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(230.7176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(263.9851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(970.2781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1025.8845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(326.5652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(182.9125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(864.1254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1093.4950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(441.1271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(129.6206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(742.7548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(567.1692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(613.8245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1137.2319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(696.7325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.8558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(485.4690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1110.5913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(821.6357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(160.1190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(365.7868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1053.1663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(933.9926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(231.5889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(262.3291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(968.5781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1026.7075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(327.7514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(181.6229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(862.1627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1093.9257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(442.5336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(128.7591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(740.6339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.4006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(568.6880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.0718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(611.6597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.7648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(698.2484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(117.9268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(483.3783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1109.6769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(823.0345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(160.6362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(363.8836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1051.8435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(935.1670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(232.5014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(260.7153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(966.9124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1027.5658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(328.9839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(180.3828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(860.2420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1094.3965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(443.9914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(127.9542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(738.5627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.4380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(570.2621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.7364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(609.5528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.3502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(699.8237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(118.0664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(481.3528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1108.8207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(824.4968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(161.2270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(362.0528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1050.5856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(936.4095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(233.4921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(259.1807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(965.3182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1028.4966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(330.2985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(179.2281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(858.3995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1094.9437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(445.5345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(127.2401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(736.5760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.5555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(571.9248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.4967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(607.5362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.0197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(701.4905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(118.3059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(479.4235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1108.0536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(826.0527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(161.9213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(360.3234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1049.4211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(937.7480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(234.5890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(257.7525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(963.8224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1029.5255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(331.7216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(178.1843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(856.6598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1095.5923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(447.1876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(126.6406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(734.6970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1131.7767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(573.6988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.3744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(605.6314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.7955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(703.2693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(118.6649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(477.6097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1107.3948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(827.7209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(162.7363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(358.7129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1048.3677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(939.1988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(235.8071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(256.4459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(962.4394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1030.6666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(333.2657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(177.2639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(855.0351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1096.3521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(448.9610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(126.1657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(732.9344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1132.1090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(575.5912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.3773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(603.8448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.6825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(705.1649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(119.1487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(475.9162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1106.8478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(829.5043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(163.6750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(357.2236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1047.4257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(940.7626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(237.1472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(255.2608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(961.1688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1031.9187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(334.9292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(176.4646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(853.5226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1097.2208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(450.8507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.8108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(731.2842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1132.5486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(577.5969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.4982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(602.1705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.6741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(707.1694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(119.7479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(474.3329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1106.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(831.3923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(164.7258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(355.8431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1046.5836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(942.4266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(238.5952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(254.1823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(959.9951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1033.2664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(336.6958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(175.7694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(852.1053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1098.1804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(452.8382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.5567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(729.7259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1133.0740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(579.6945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.7160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(600.5848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.7474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(709.2598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(120.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(472.8361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1106.0347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(833.3596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(165.8632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(354.5456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1045.8141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(944.1633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(240.1238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(253.1831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(958.8903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1034.6802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(338.5365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(175.1492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(850.7520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1099.1998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(454.8929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.3725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(728.2283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1133.6531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(581.8516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(106.9981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(599.0558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.8682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(711.4021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(121.1888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(471.3910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1105.7085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(835.3710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(167.0522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(353.2953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1045.0815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(945.9366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(241.6967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(252.2260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(957.8164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1036.1229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(340.4138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(174.5656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(849.4249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1100.2408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(456.9760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.2193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(726.7517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1134.2466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(584.0291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(597.5434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.9974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(713.5571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(121.9561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(469.9579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1105.3849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(837.3867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(168.2516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(352.0516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1044.3446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(947.7052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(243.2722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(251.2699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(956.7331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1037.5532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(342.2859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(173.9772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(848.0829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1101.2622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(459.0456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.0551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(725.2552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1134.8132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(586.1847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(596.0052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.0918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(715.6810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(122.6992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(468.4938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1105.0203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(839.3635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(169.4197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(350.7723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1043.5620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(949.4280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(244.8090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(250.2736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(955.5986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1038.9298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(344.1116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(173.3435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(846.6852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1102.2223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(461.0614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(124.8401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(723.6986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.3126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(588.2787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(594.4035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.1143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(717.7363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(123.3800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(466.9622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1104.5781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(841.2648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(170.5195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(349.4214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1042.6971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(951.0685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(246.2719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(249.2015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(954.3785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1040.2186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(345.8570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(172.6301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(845.1982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1103.0891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(462.9906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(124.5416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(722.0495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.7135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(590.2806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(592.7062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.0337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(719.6937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(123.9692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(465.3333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1104.0300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(843.0621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(171.5234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(347.9713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1041.7233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(952.5999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(247.6340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(248.0287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(953.0474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1041.3938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(347.4974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(171.8141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(843.5991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1103.8394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(464.8108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(124.1384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(720.2877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.9954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(592.1694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(590.8959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.8319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(721.5342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(124.4496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(463.5911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1103.3594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(844.7402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(172.4165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(346.4081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1040.6270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(954.0099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(248.8833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(246.7428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(951.5940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1042.4457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(349.0233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(170.8854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(841.8790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1104.4652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(466.5145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(123.6231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(718.4063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.1523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(593.9402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(588.9683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.5063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(723.2561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(124.8187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(461.7337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1102.5660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(846.2990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(173.1985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(344.7322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1039.4100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(955.3002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(250.0222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(245.3469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(950.0223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1043.3788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(350.4390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(169.8495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(840.0434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1104.9727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(468.1089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(123.0032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(716.4131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.1931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(595.6028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(586.9329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1135.0667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(724.8706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.0887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(459.7731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1101.6621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(847.7514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(173.8842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(342.9579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1038.0862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(956.4868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(251.0673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(243.8578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(948.3491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1044.2101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(351.7637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(168.7253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(838.1119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1105.3826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(469.6147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(122.3002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(714.3303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.1395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(597.1792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(584.8144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1134.5378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(726.4024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.2849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(457.7363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1100.6750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(849.1249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(174.5007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(341.1140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1036.6855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(957.5978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(252.0474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(242.3056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(946.6052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1044.9707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(353.0276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(167.5447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(836.1169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1105.7267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(471.0644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(121.5469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(712.1915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1136.0267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(598.7040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(582.6475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1133.9552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(727.8869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(125.4430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(455.6586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1099.6405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(850.4559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(175.0846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(339.2370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(1035.2446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(958.6709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(253.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(240.7281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(944.8288, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad = True)\n",
    "b = torch.rand(1, requires_grad = True)\n",
    "print('Initial parameters:', a, b)\n",
    "learning_rate = 0.0001\n",
    "for i in range(1000):\n",
    "    predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)\n",
    "    loss = torch.mean((predictions - y_train) ** 2)\n",
    "    print('loss:', loss)\n",
    "    loss.backward()\n",
    "    a.data.add_(- learning_rate * a.grad.data)\n",
    "    b.data.add_(- learning_rate * b.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过打印输出的loss结果来看，存在着非常大的震荡，从而导致无法正确估计参数a和b的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. 正确版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: [tensor([0.7887], requires_grad=True), tensor([0.1422], requires_grad=True)]\n",
      "loss: tensor(219.7371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(132.3882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(114.0625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(110.2176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.4107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.2412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.2054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.1001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(109.0000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.9001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.8001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7920, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.7001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6920, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.6001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.5001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4789, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.4002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3870, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.3001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2789, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.2001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1789, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.1002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0870, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(108.0001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9870, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.9000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8870, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.8000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7920, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7250, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7065, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7009, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.7000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6920, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6902, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6526, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6353, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6192, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6100, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6082, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.6000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5991, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5870, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5749, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5580, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5385, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5365, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5271, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5238, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5221, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5188, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5176, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5159, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5129, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5112, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5095, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5052, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5034, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5022, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5004, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.5000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4978, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4883, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4857, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4810, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4783, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4707, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4678, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4625, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4604, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4595, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4565, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4469, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4402, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4374, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4370, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4359, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4348, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4343, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4337, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4333, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4326, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4321, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4315, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4310, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4304, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4299, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4293, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4288, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4282, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4277, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4266, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4261, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4254, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4244, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4233, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4227, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4216, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4210, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4204, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4199, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4182, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4170, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4164, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4153, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4147, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4141, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4135, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4124, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4117, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4106, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4088, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4076, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4070, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4058, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4047, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4040, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4027, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4016, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.4000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3997, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3984, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3971, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3966, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3959, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3954, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3948, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3940, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3934, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3928, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3922, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3915, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3909, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3896, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3890, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3876, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3863, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3850, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3844, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3836, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3830, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3823, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3816, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3803, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3796, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3789, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3776, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3769, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3762, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3755, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3741, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3734, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3726, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3720, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3713, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3698, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3692, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3684, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3670, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3662, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3656, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3648, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3640, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3633, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3619, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3611, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3588, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3573, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3556, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3549, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3542, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3535, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3518, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3509, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3502, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3493, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3486, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3479, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3461, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3453, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3445, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3436, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3428, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3419, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3410, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3394, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3379, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3378, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3377, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3376, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3375, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3373, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3372, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3371, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3369, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3368, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3367, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3366, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3364, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3363, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3362, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3361, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3360, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3358, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3357, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3356, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3355, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3354, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3352, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3351, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3350, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3349, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3347, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3346, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3345, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3344, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3342, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3341, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3340, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3339, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3338, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3336, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3335, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3334, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3332, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3331, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3330, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3329, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3328, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3327, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3325, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3324, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3323, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3322, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3320, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3319, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3318, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3317, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3316, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3314, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3313, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3312, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3311, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3309, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3308, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3307, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3306, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3305, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3303, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3302, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3301, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3300, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3298, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3297, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3296, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3295, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3294, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3292, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3291, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3290, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3289, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3287, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3286, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3285, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3284, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3283, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3281, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3280, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3279, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3278, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3276, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3275, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3274, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3273, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3272, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3270, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3269, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3268, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3267, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3265, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3264, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3263, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3262, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3260, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3259, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3258, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3257, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3256, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3255, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3253, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3252, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3251, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3249, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3248, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3247, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3246, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3245, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3243, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3242, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3241, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3240, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3239, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3237, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3236, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3235, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3234, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3232, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3231, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3230, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3229, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3228, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3226, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3225, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3224, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3223, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3222, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3220, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3219, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3218, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3217, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3215, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3214, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3213, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3212, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3211, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3209, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3208, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3207, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3206, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3205, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3203, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3202, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3201, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3200, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3198, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3197, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3196, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3195, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3194, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3193, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3191, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3190, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3189, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3187, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3186, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3185, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3184, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3183, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3181, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3180, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3179, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3178, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3177, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3175, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3174, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3173, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3172, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3171, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3169, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3168, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3167, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3166, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3165, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3163, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3162, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3161, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3160, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3158, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3157, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3156, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3155, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3154, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3152, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3151, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3150, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3149, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3148, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3146, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3145, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3144, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3143, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3142, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3140, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3139, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3138, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3137, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3136, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3134, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3133, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3132, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3131, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3130, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3128, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3127, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3126, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3125, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3123, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3122, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3121, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3120, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3119, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3118, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3116, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3115, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3114, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3113, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3111, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3110, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3109, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3108, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3107, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3105, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3104, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3103, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3102, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3101, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3099, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3098, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3097, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3096, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3094, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3093, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3092, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3091, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3090, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3089, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3087, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3086, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3085, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3084, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3083, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3081, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3080, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3079, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3078, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3077, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3075, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3074, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3073, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3072, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3071, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3069, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3068, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3067, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3066, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3064, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3063, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3062, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3061, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3060, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3059, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3057, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3056, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3055, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3054, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3053, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3051, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3050, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3049, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3048, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3046, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3045, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3044, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3043, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3042, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3041, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3039, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3038, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3037, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3036, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3035, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3033, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3032, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3031, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3030, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3029, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3028, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3026, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3025, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3024, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3023, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3021, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3020, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3019, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3018, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3017, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3015, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3014, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3013, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3012, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3011, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3010, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3008, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3007, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3006, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3005, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3003, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3002, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3001, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.3000, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2999, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2998, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2996, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2995, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2994, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2993, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2992, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2990, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2989, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2988, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2987, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2986, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2985, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2983, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2982, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2981, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2980, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2979, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2977, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2976, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2975, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2974, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2973, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2972, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2970, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2969, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2968, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2967, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2965, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2964, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2963, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2962, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2961, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2960, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2958, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2957, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2956, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2955, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2953, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2952, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2951, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2950, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2949, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2947, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2946, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2945, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2944, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2943, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2942, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2941, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2939, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2938, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2937, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2936, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2935, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2933, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2932, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2931, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2930, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2929, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2927, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2926, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2925, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2924, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2923, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2921, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2920, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2919, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2918, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2917, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2916, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2914, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2913, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2912, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2911, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2910, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2908, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2907, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2906, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2905, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2904, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2903, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2901, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2900, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2899, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2898, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2897, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2895, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2894, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2893, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2892, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2891, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2889, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2888, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2887, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2886, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2885, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2884, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2882, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2881, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2880, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2879, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2878, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2877, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2875, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2874, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2873, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2872, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2871, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2869, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2868, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2867, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2866, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2865, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2864, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2862, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2861, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2860, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2859, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2858, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2856, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2855, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2854, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2853, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2852, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2851, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2849, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2848, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2847, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2846, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2845, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2843, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2842, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2841, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2840, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2839, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2838, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2837, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2835, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2834, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2833, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2832, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2831, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2829, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2828, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2827, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2826, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2825, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2824, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2822, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2821, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2820, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2819, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2818, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2817, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2815, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2814, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2813, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2812, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2811, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2809, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2808, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2807, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2806, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2805, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2804, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2802, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2801, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2800, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2799, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2798, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2797, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2795, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2794, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2793, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2792, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2791, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2790, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2788, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2787, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2786, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2785, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2784, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2782, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2781, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2780, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2779, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2778, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2777, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2775, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2774, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2773, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2772, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2771, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2770, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2768, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2767, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2766, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2765, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2764, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2763, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2761, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2760, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2759, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2758, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2757, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2756, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2754, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2753, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2752, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2751, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2750, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2748, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2747, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2746, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2745, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2744, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2743, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2742, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2740, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2739, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2738, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2737, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2736, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2735, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2733, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2732, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2731, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2730, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2729, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2728, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2727, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2725, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2724, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2723, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2722, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2721, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2719, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2718, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2717, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2716, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2715, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2714, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2712, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2711, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2710, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2709, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2708, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2706, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2705, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2704, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2703, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2702, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2701, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2700, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2699, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2697, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2696, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2695, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2694, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2693, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2691, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2690, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2689, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2688, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2687, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2686, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2685, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2683, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2682, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2681, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2680, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2679, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2677, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2676, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2675, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2674, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2673, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2672, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2671, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2669, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2668, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2667, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2666, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2665, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2664, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2663, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2661, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2660, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2659, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2658, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2657, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2655, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2654, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2653, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2652, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2651, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2650, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2649, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2647, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2646, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2645, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2644, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2643, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2642, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2641, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2639, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2638, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2637, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2636, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2635, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2634, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2632, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2631, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2630, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2629, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2628, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2627, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2626, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2624, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2623, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2622, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2621, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2620, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2618, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2617, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2616, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2615, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2614, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2613, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2612, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2610, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2609, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2608, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2607, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2606, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2605, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2603, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2602, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2601, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2600, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2599, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2598, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2597, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2596, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2594, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2593, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2592, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2591, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2590, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2589, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2587, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2586, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2585, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2584, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2583, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2582, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2581, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2579, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2578, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2577, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2576, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2575, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2574, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2572, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2571, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2570, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2569, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2568, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2567, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2566, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2564, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2563, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2562, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2561, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2560, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2559, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2558, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2557, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2555, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2554, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2553, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2552, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2551, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2550, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2548, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2547, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2546, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2545, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2544, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2543, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2541, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2540, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2539, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2538, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2537, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2536, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2534, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2533, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2532, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2531, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2530, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2529, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2528, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2527, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2525, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2524, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2523, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2522, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2521, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2520, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2519, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2517, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2516, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2515, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2514, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2513, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2512, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2511, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2510, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2508, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2507, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2506, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2505, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2504, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2503, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2501, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2500, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2499, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2498, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2497, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2496, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2495, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2494, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2492, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2491, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2490, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2489, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2488, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2487, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2485, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2484, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2483, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2482, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2481, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2480, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2478, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2477, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2476, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2475, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2474, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2473, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2472, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2471, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2470, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2468, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2467, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2466, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2465, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2464, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2463, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2462, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2460, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2459, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2458, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2457, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2456, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2455, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2454, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2452, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2451, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2450, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2449, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2448, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2447, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2446, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2444, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2443, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2442, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2441, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2440, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2439, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2438, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2437, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2435, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2434, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2433, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2432, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2431, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2430, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2429, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2427, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2426, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2425, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2424, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2423, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2422, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2421, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2420, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2418, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2417, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2416, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2415, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2414, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2413, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2412, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2411, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2409, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2408, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2407, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2406, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2405, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2404, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2403, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2401, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2400, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2399, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2398, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2397, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2396, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2395, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2393, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2392, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2391, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2390, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2389, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2388, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2387, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2386, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2384, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2383, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2382, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2381, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2380, grad_fn=<MeanBackward0>)\n",
      "loss: tensor(107.2379, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(1, requires_grad = True) #创建a变量，并随机赋值初始化\n",
    "b = torch.rand(1, requires_grad = True) #创建b变量，并随机赋值初始化\n",
    "print('Initial parameters:', [a, b])\n",
    "learning_rate = 0.0001 #设置学习率\n",
    "for i in range(10000):\n",
    "    predictions = a.expand_as(x_train) * x_train + b.expand_as(x_train)  #计算在当前a、b条件下的模型预测数值\n",
    "    loss = torch.mean((predictions - y_train) ** 2) #通过与标签数据y比较，计算误差\n",
    "    print('loss:', loss)\n",
    "    loss.backward() #对损失函数进行梯度反传\n",
    "    a.data.add_(- learning_rate * a.grad.data)  #利用上一步计算中得到的a的梯度信息更新a中的data数值\n",
    "    b.data.add_(- learning_rate * b.grad.data)  #利用上一步计算中得到的b的梯度信息更新b中的data数值\n",
    "    ### 增加了这部分代码，清空存储在变量a，b中的梯度信息，以免在backward的过程中会反复不停地累加\n",
    "    a.grad.data.zero_() #清空a的梯度数值\n",
    "    b.grad.data.zero_() #清空b的梯度数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9677], requires_grad=True)\n",
      "tensor([1.5306], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "\n",
    "x_data = x_train.data.numpy() # 获得x包裹的数据\n",
    "plt.figure(figsize = (10, 7)) #设定绘图窗口大小\n",
    "xplot, = plt.plot(x_data, y_train.numpy(), 'o') # 绘制原始数据\n",
    "yplot, = plt.plot(x_data, a.data.numpy() * x_data + b.data.numpy())  #绘制拟合数据\n",
    "plt.xlabel('X') #更改坐标轴标注\n",
    "plt.ylabel('Y') #更改坐标轴标注\n",
    "str1 = str(a.data.numpy()[0]) + 'x +' + str(b.data.numpy()[0]) #图例信息\n",
    "plt.legend([xplot, yplot],['Data', str1]) #绘制图例\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([89.5014, 90.4789, 91.4563, 92.4338, 93.4112, 94.3887, 95.3661, 96.3436,\n",
       "        97.3210, 98.2985], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = a.expand_as(x_test) * x_test + b.expand_as(x_test) #计算模型的预测结果\n",
    "predictions #输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_data = x_train.data.numpy() # 获得x包裹的数据\n",
    "x_pred = x_test.data.numpy()\n",
    "plt.figure(figsize = (10, 7)) #设定绘图窗口大小\n",
    "plt.plot(x_data, y_train.data.numpy(), 'o') # 绘制训练数据\n",
    "plt.plot(x_pred, y_test.data.numpy(), 'p') # 绘制测试数据\n",
    "x_data = np.r_[x_data, x_test.data.numpy()]\n",
    "plt.plot(x_data, a.data.numpy() * x_data + b.data.numpy())  #绘制拟合数据\n",
    "plt.plot(x_pred, a.data.numpy() * x_pred + b.data.numpy(), 'x') #绘制预测数据\n",
    "plt.xlabel('X') #更改坐标轴标注\n",
    "plt.ylabel('Y') #更改坐标轴标注\n",
    "str1 = str(a.data.numpy()[0]) + 'x +' + str(b.data.numpy()[0]) #图例信息\n",
    "plt.legend([xplot, yplot],['Data1', str1]) #绘制图例\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "本文件是集智AI学园http://campus.swarma.org 出品的“火炬上的深度学习”第II课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
