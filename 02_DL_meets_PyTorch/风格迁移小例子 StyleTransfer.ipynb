{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 风格迁移PyTorch示例代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在这里可以输入原始图像文件（内容以及风格）的位置，注意两张图片 要大小相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#风格图像\n",
    "style = 'images/escher.jpg'\n",
    "\n",
    "#内容图像\n",
    "content = 'images/portrait1.jpg'\n",
    "\n",
    "#注意，这两张图片必须同样大小\n",
    "\n",
    "#希望得到的图片大小（越大越清晰，计算越慢）\n",
    "imsize = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读入图片文件部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要的包\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 是否用GPU计算，如果检测到有安装好的GPU，则利用它来计算\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print( 'use cuda:', use_cuda)\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用PyTorch自带的图形处理包torchvision.transform加载图像文件，并作预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "    transforms.Resize (imsize),  # 将加载的图像转变为指定的大小\n",
    "    transforms.ToTensor()])  # 将图像转化为tensor\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = torch.tensor(loader(image), requires_grad = True)\n",
    "    # 为了适应卷积网络的需要，虚拟一个batch的维度\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "style_img = image_loader(style).type(dtype)\n",
    "content_img = image_loader(content).type(dtype)\n",
    "\n",
    "assert style_img.size() == content_img.size(), \\\n",
    "    \"我们需要输入相同尺寸的风格和内容图像\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在浏览器中展示这两张图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unloader = transforms.ToPILImage()  # 将其转化为PIL图像（Python Imaging Library） \n",
    "\n",
    "plt.ion()\n",
    "\n",
    "def imshow(tensor, title=None):\n",
    "    image = tensor.clone().cpu()  # 克隆Tensor防止改变\n",
    "    image = image.view(3, imsize, imsize)  # 删除添加的batch曾\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001) # 停一会以便更新视图\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "imshow(style_img.data, title='Style Image')\n",
    "\n",
    "plt.figure()\n",
    "imshow(content_img.data, title='Content Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义主要的计算函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算内容损失函数\n",
    "class ContentLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, target, weight):\n",
    "        super(ContentLoss, self).__init__()\n",
    "        # 由于网络的权重都是从target上迁移过来，所以在计算梯度的时候，需要把它和原始计算图分离\n",
    "        self.target = target.detach() * weight\n",
    "        self.weight = weight\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        # 误差就是当前计算的内容与target之间的均方误差\n",
    "        self.loss = self.criterion(input * self.weight, self.target)\n",
    "        self.output = input\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, retain_variables=True):\n",
    "        # 开始进行反向传播算法\n",
    "#         self.loss.backward(retain_variables=retain_variables)\n",
    "        self.loss.backward(retain_graph=True)\n",
    "        return self.loss\n",
    "    \n",
    "class GramMatrix(nn.Module):\n",
    "    # 计算Gram矩阵，该矩阵衡量的是任意两个特征层之间，每一个对应像素的相似度\n",
    "\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()  # a=batch size(=1)\n",
    "        # b=特征图的数量\n",
    "        # (c,d)=特征图的图像尺寸 (N=c*d)\n",
    "\n",
    "        features = input.view(a * b, c * d)  # 将特征图图像扁平化为一个向量\n",
    "\n",
    "        G = torch.mm(features, features.t())  # 计算gram乘积\n",
    "\n",
    "        # 我们通过除以特征图中的像素数量来归一化特征图\n",
    "        return G.div(a * b * c * d)\n",
    "    \n",
    "class StyleLoss(nn.Module):\n",
    "    \n",
    "    # 计算风格损失的函数\n",
    "\n",
    "    def __init__(self, target, weight):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.target = target.detach() * weight\n",
    "        self.weight = weight\n",
    "        self.gram = GramMatrix()\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.output = input.clone()\n",
    "        # 计算本图像的gram矩阵，并将它与target对比\n",
    "        self.G = self.gram(input)\n",
    "        self.G.mul_(self.weight)\n",
    "        self.loss = self.criterion(self.G, self.target)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, retain_variables=True):\n",
    "#         self.loss.backward(retain_variables=retain_variables)\n",
    "        self.loss.backward(retain_graph=True)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 迁移学习，从网络上下载vgg19网络并加载\n",
    "### vgg19网络是一种特殊的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.vgg19(pretrained=True).features\n",
    "\n",
    "# 如果可能就用GPU计算:\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义主要的内容、风格损失函数计算模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 希望计算的内容或者风格层 :\n",
    "content_layers_default = ['conv_4']\n",
    "#style_layers_default = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "style_layers_default = ['conv_4']\n",
    "\n",
    "#该函数定义模型\n",
    "def get_style_model_and_losses(cnn, style_img, content_img,\n",
    "                               style_weight=1000, content_weight=1,\n",
    "                               content_layers=content_layers_default,\n",
    "                               style_layers=style_layers_default):\n",
    "    #传进来的参数包括cnn：迁移学习得来的vgg19网络，风格图片，内容图片，相对风格、内容权重，默认的内容层数据，默认的风格层数据\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "\n",
    "    # 定义列表存储每一个周期的计算损失\n",
    "    content_losses = []\n",
    "    style_losses = []\n",
    "\n",
    "    model = nn.Sequential()  # 一个新的序贯网络模型\n",
    "    gram = GramMatrix()  # 我们需要gram模块来计算风格目标函数\n",
    "\n",
    "    # 如果有GPU就把这些计算挪到GPU上:\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        gram = gram.cuda()\n",
    "\n",
    "    # 将每层卷积核的数据都加载到新的网络模型上来\n",
    "    i = 1\n",
    "    for layer in list(cnn):\n",
    "        if isinstance(layer, nn.Conv2d):\n",
    "            name = \"conv_\" + str(i)\n",
    "            model.add_module(name, layer)\n",
    "\n",
    "            if name in content_layers:\n",
    "                # 如果当前层模型在定义好的要计算内容的层:\n",
    "                target = model(content_img).clone() #将内容图像当前层的feature信息拷贝到target中\n",
    "                content_loss = ContentLoss(target, content_weight) #定义content_loss的目标函数\n",
    "                model.add_module(\"content_loss_\" + str(i), content_loss) #在新网络上加content_loss层\n",
    "                content_losses.append(content_loss)\n",
    "\n",
    "            if name in style_layers:\n",
    "                # 如果当前层在指定的风格层中，进行风格层损失的计算\n",
    "                target_feature = model(style_img).clone()\n",
    "                target_feature_gram = gram(target_feature)\n",
    "                style_loss = StyleLoss(target_feature_gram, style_weight)\n",
    "                model.add_module(\"style_loss_\" + str(i), style_loss)\n",
    "                style_losses.append(style_loss)\n",
    "\n",
    "        if isinstance(layer, nn.ReLU):\n",
    "            #如果不是卷积层，则做同样处理\n",
    "            name = \"relu_\" + str(i)\n",
    "            model.add_module(name, layer)\n",
    "\n",
    "            if name in content_layers:\n",
    "                # add content loss:\n",
    "                target = model(content_img).clone()\n",
    "                content_loss = ContentLoss(target, content_weight)\n",
    "                model.add_module(\"content_loss_\" + str(i), content_loss)\n",
    "                content_losses.append(content_loss)\n",
    "\n",
    "            if name in style_layers:\n",
    "                # add style loss:\n",
    "                target_feature = model(style_img).clone()\n",
    "                target_feature_gram = gram(target_feature)\n",
    "                style_loss = StyleLoss(target_feature_gram, style_weight)\n",
    "                model.add_module(\"style_loss_\" + str(i), style_loss)\n",
    "                style_losses.append(style_loss)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        if isinstance(layer, nn.MaxPool2d):\n",
    "            name = \"pool_\" + str(i)\n",
    "            model.add_module(name, layer)  # ***\n",
    "\n",
    "    return model, style_losses, content_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 待调整的图像可以是原始的内容图，也可以是一张噪声图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = content_img.clone()\n",
    "# 如果想从调整一张噪声图像开始，请用下面一行的代码\n",
    "#input_img = torch.randn(content_img.data.size()).type(dtype)\n",
    "\n",
    "# 将选中的待调整图打印出来:\n",
    "plt.figure()\n",
    "imshow(input_img.data, title='Input Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_param_optimizer(input_img):\n",
    "    # 注意待优化的变量不再是神经网络的权重，而是输入图像input_img的内容本身\n",
    "    input_param = nn.Parameter(input_img.data)\n",
    "    optimizer = optim.LBFGS([input_param])\n",
    "    return input_param, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行算法的主过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_style_transfer(cnn, content_img, style_img, input_img, num_steps=300,\n",
    "                       style_weight=1000, content_weight=1):\n",
    "    #输入参数包括cnn网络，内容图像、风格图像、算法迭代步数，风格和内容的相对权重，默认1000:1\n",
    "    \"\"\"运行风格迁移的主算法过程.\"\"\"\n",
    "    print('正在构造风格迁移模型..')\n",
    "    model, style_losses, content_losses = get_style_model_and_losses(cnn,\n",
    "        style_img, content_img, style_weight, content_weight)\n",
    "    input_param, optimizer = get_input_param_optimizer(input_img)\n",
    "\n",
    "    print('开始优化..')\n",
    "    run = [0]\n",
    "    while run[0] <= num_steps:\n",
    "\n",
    "        def closure():\n",
    "            # correct the values of updated input image\n",
    "            input_param.data.clamp_(0, 1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            model(input_param)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "\n",
    "            for sl in style_losses:\n",
    "                style_score += sl.backward()\n",
    "            for cl in content_losses:\n",
    "                content_score += cl.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % 50 == 0:\n",
    "                print(\"运行 {}轮:\".format(run))\n",
    "                print('风格损失 : {:4f} 内容损失: {:4f}'.format(\n",
    "                    style_score.data.item(), content_score.data.item()))\n",
    "                print()\n",
    "\n",
    "            return style_score + content_score\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    # 做一些修正，防止数据超界...\n",
    "    input_param.data.clamp_(0, 1)\n",
    "\n",
    "    return input_param.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 展示最终结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 最终运行算法过程\n",
    "output = run_style_transfer(cnn, content_img, style_img, input_img, num_steps=300, style_weight=1000, content_weight=1)\n",
    "\n",
    "# 展示最终结果\n",
    "plt.figure()\n",
    "imshow(output, title='Output Image')\n",
    "\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
